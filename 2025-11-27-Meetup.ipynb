{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "108937ff",
   "metadata": {},
   "source": [
    "# <del>Kafi Streams - Complex Stream Processing on Python Without the Complexity<del>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5869f",
   "metadata": {},
   "source": [
    "# Stream Processing Unchained\n",
    "### (and a very very early prototype of Kafi Streams)\n",
    "#### Ralph Debusmann (Migros-Genossenschafts-Bund)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad0f5b",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed26abf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1 The Stream Processing Crisis\n",
    "\n",
    "## The Commercial Side\n",
    "\n",
    "### Confluent + Flink\n",
    "\n",
    "* Projected Confluent ARR FY 2025 $1B+\n",
    "* Flink ARR FY 2025 $14M? (https://bigdata.2minutestreaming.com/p/event-streaming-is-topping-out) - that would be about 1.4% (but QoQ growth 70%)\n",
    "\n",
    "### Lots of startups, none of them really close to the hockey stick\n",
    "\n",
    "(in alphabetical order)\n",
    "\n",
    "* Arroyo (acquired by Cloudflare)\n",
    "* Bytewax\n",
    "* Decodable\n",
    "* DeltaStream\n",
    "* Feldera\n",
    "* Materialize\n",
    "* Pathway\n",
    "* Quix\n",
    "* Responsive\n",
    "* RisingWave\n",
    "* Timeplus\n",
    "\n",
    "### Bigger companies, but is their focus really on stream processing?\n",
    "\n",
    "* Databricks\n",
    "* MongoDB\n",
    "* Snowflake\n",
    "* Ververica\n",
    "\n",
    "## The Lakehouse Trend\n",
    "\n",
    "### Multimodal streams\n",
    "\n",
    "* Aiven/Apache Kafka (Iceberg Topics)\n",
    "* Confluent (Tableflow)\n",
    "* Redpanda (Iceberg Topics)\n",
    "\n",
    "### With that, it seems that processing also shifts to the lakehouse\n",
    "\n",
    "* Confluent (Real-time Context Engine for Kafka/Iceberg)\n",
    "* Ververica (Fluss/Paimon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803cba30",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37a2e7",
   "metadata": {},
   "source": [
    "# 2 Why?\n",
    "\n",
    "## Few Real Real-time Use Cases\n",
    "\n",
    "* Sure, fraud detection et al., sure in banking, online retail, but beyond?\n",
    "* E.g. at Migros, <5% real-time use cases.\n",
    "\n",
    "## Stream Processing Is Still Hard\n",
    "\n",
    "* Just talk to someone who implements Kafka Streams/Flink pipelines...\n",
    "* ...if you can even find someone who is well-versed enough to do it (and whom you can actually pay).\n",
    "* And then, try to debug these pipelines if they fail.\n",
    "* In the end, it is just extremely costly and is only worth it for an even smaller subset of real-time use cases.\n",
    "\n",
    "## For the Most Part, Stream Processing Is Not Even Consistent\n",
    "\n",
    "* The leading stream processing systems (Kafka Streams/Flink) are *eventually* consistent.\n",
    "* So if you need stronger consistency guarantees, things get even hairier. You need workarounds. Even more complexity.\n",
    "* Strongly consistent stream processing frameworks exist (but have low adoption):\n",
    "  * Bytewax (Timely Dataflow)\n",
    "  * Feldera (Database Stream Processor)\n",
    "  * Materialize, Pathway (Differential Dataflow)\n",
    "* Let's have a look at Jamie Brandon's consistency benchmark... (DEMO - Flink + Materialize/Feldera)\n",
    "\n",
    "## So, Let's Take The Escape Route And Go Back To Batch?\n",
    "\n",
    "* That's where it seems to go now, also with Confluent...\n",
    "* ...see \"The Lakehouse Trend\" above.\n",
    "* But do you also think we should give up? Go back to batch? Go back to \"just push all the data into a database/lakehouse and be happy as in the world before stream processing\"?\n",
    "\n",
    "## I Won't. I Still Believe In Stream Processing\n",
    "\n",
    "* I believe in incremental computation (=only compute deltas, never compute anything twice).\n",
    "* I believe in push and not only pull queries.\n",
    "* I believe in true shift-left architecture (as in - not shifting the technology left (lakehouse) but bringing the data from the lakehouse to streaming)\n",
    "* I believe in simplicity and Occam's Razor (as in - not having to introduce another complexity monster (e.g. Iceberg) to the data streaming platform).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8c4bc",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85401233",
   "metadata": {},
   "source": [
    "# 3 It Is Time To Unchain Stream Processing\n",
    "\n",
    "## Is This Even Possible? We Can At Least Have A Go, No?\n",
    "\n",
    "* Let's go back to Differential Dataflow (DD; McSherry 2014) and Database Stream Processor (DBSP; Budiu et al. 2022).\n",
    "* Low adoption, yes, but does this mean we should keep ignoring them?\n",
    "* Who of you as ever used one of them?\n",
    "* Do you even know what they are about?\n",
    "\n",
    "## This Is Not About Streaming Databases\n",
    "\n",
    "* Yes, I've co-written a book about this ;)\n",
    "* Both theories are based on database theory.\n",
    "* The first commercial stream processing system based on DD was a streaming database (Materialize).\n",
    "* But this is not the point. Bytewax, Feldera and Pathway are, for example, stream processors, not streaming databases.\n",
    "* Materialized Views are *not* a prerequisite for strong consistency guarantees.\n",
    "\n",
    "## But What Is the Point?\n",
    "\n",
    "* There are three points/prerequisites for strongly consistent stream processing (as in a database):\n",
    "  * You need some kind of global virtual \"clock\". Makes it harder to build a distributed system. But which use cases need to be ultra-scalable? Isn't there are also a trend towards less distributed systems (see e.g. DuckDB)?\n",
    "  * You need more state (at least you accept that you don't forget too quickly).\n",
    "  * You need a proper theory aka stream processing engine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef96a0",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c6a9a",
   "metadata": {},
   "source": [
    "# 4 Towards A Kafka Streams For Python Based On DBSP"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

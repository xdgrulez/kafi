{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "108937ff",
   "metadata": {},
   "source": [
    "# <del>Kafi Streams - Complex Stream Processing on Python Without the Complexity<del>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5869f",
   "metadata": {},
   "source": [
    "# Stream Processing Unchained\n",
    "### (and a very very early prototype of Kafi Streams)\n",
    "#### Ralph Debusmann (Migros-Genossenschafts-Bund)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad0f5b",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed26abf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1 The Stream Processing Crisis\n",
    "\n",
    "\n",
    "## The Commercial Side\n",
    "\n",
    "### Confluent + Flink\n",
    "\n",
    "* Projected Confluent ARR FY 2025 $1B+\n",
    "* Flink ARR FY 2025 $14M? (https://bigdata.2minutestreaming.com/p/event-streaming-is-topping-out) - that would be about 1.4% (but QoQ growth 70%)\n",
    "\n",
    "### Lots of startups, none of them really close to the hockey stick\n",
    "\n",
    "(in alphabetical order)\n",
    "\n",
    "* Arroyo (acquired by Cloudflare)\n",
    "* Bytewax\n",
    "* Decodable\n",
    "* DeltaStream\n",
    "* Feldera\n",
    "* Materialize\n",
    "* Pathway\n",
    "* Quix\n",
    "* Responsive\n",
    "* RisingWave\n",
    "* Timeplus\n",
    "\n",
    "### Some bigger companies, but is their focus really on stream processing?\n",
    "\n",
    "* Databricks\n",
    "* MongoDB\n",
    "* Snowflake\n",
    "* Ververica\n",
    "\n",
    "## The Lakehouse Trend\n",
    "\n",
    "### Multimodal streams\n",
    "\n",
    "* Aiven/Apache Kafka (Iceberg Topics)\n",
    "* Confluent (Tableflow)\n",
    "* Redpanda (Iceberg Topics)\n",
    "\n",
    "### With that, it seems that processing is also shifting to the lakehouse\n",
    "\n",
    "* Confluent (Real-time Context Engine for Kafka/Iceberg)\n",
    "* RisingWave (lots of Iceberg stuff, e.g. RisingWave Iceberg catalog)\n",
    "* Ververica (Fluss/Paimon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803cba30",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37a2e7",
   "metadata": {},
   "source": [
    "# 2 Why Is Stream Processing Losing Its Momentum?\n",
    "\n",
    "* aka \"Why Hasn't Stream Processing Ever Really Taken Off?\"\n",
    "\n",
    "* aka \"Why Do People Still Use Databases For Data Processing?\"\n",
    "\n",
    "## Few Real Real-time Use Cases\n",
    "\n",
    "* Sure, fraud detection et al., sure in banking, online retail, but beyond?\n",
    "\n",
    "* E.g. at Migros, <5% real-time use cases.\n",
    "\n",
    "## Stream Processing Is Still Hard\n",
    "\n",
    "* Just talk to someone who implements Kafka Streams/Flink pipelines...\n",
    "\n",
    "* ...if you can even find someone who is well-versed enough to do it (and whom you can actually pay).\n",
    "\n",
    "* And then, try to debug these pipelines if they fail.\n",
    "\n",
    "* In the end, it is just extremely costly and is only worth it for an even smaller subset of real-time use cases.\n",
    "\n",
    "## For the Most Part, Stream Processing Is Not Even Consistent\n",
    "\n",
    "* The leading stream processing systems/\"classical stream processing\" (Kafka Streams/Flink) are *eventually* consistent.\n",
    "\n",
    "* So if you need stronger consistency guarantees, things get even hairier. You need workarounds. Add even more complexity.\n",
    "\n",
    "* Strongly consistent stream processing frameworks exist (but have low adoption):\n",
    "  * Bytewax (Timely Dataflow)\n",
    "  * Feldera (Database Stream Processor)\n",
    "  * Materialize, Pathway (Differential Dataflow)\n",
    "\n",
    "* Let's have a look at Jamie Brandon's consistency benchmark... (https://www.scattered-thoughts.net/writing/internal-consistency-in-streaming-systems/)\n",
    "\n",
    "## So, Let's Take The Escape Route And Go Back To Batch?\n",
    "\n",
    "* That's where it seems to go now, also with Confluent...\n",
    "\n",
    "* ...see also \"The Lakehouse Trend\" above.\n",
    "\n",
    "* But do you also think we should give up?\n",
    "  * Go back to batch?\n",
    "  * Go back to \"just push all the data into a database/lakehouse and be happy as in the world before stream processing\"?\n",
    "\n",
    "## I Won't. I Still Believe In Stream Processing\n",
    "\n",
    "* I believe in incremental computation (=only compute deltas, never compute anything twice).\n",
    "\n",
    "* I believe in true shift-left architecture (as in - not shifting the technology left (lakehouse) but bringing the operational data from the lakehouse to streaming)\n",
    "\n",
    "* I believe in simplicity and Occam's Razor (as in - not having to introduce another complexity monster (e.g. Iceberg) to the data streaming platform).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8c4bc",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85401233",
   "metadata": {},
   "source": [
    "# 3 It Is Time To Unchain Stream Processing\n",
    "\n",
    "## Let's Begin With What Could Have Gone Wrong\n",
    "\n",
    "* The assumptions behind \"classical\" stream processing\n",
    "  * horizontal scaling vs. single binary\n",
    "  * local operator state/clock vs. global state/clock\n",
    "  * ad-hoc operator semantics vs. a mathematically sound theory \n",
    "\n",
    "* That is, \"classical\" stream processing is architected to trade off:\n",
    "  * extreme scale in favor of consistency and \"database-like\" semantics\n",
    "  * leaky abstractions in favor of a sound \"database-like\" abstraction (https://ralphmdebusmann.substack.com/p/why-streaming-still-isnt-mainstream)\n",
    "\n",
    "* But, the vast majority of use cases do *not* need extreme scale and would also greatly benefit from a more sound abstraction!\n",
    "\n",
    "* Some form of premature optimization?\n",
    "\n",
    "* As a result, stream processing semantics remain far detached from database semantics, so complicated that it can probably never become mainstream.\n",
    "\n",
    "* Attempts to fix this: Keep the \"classical\" stream processing engines as your basis, try to hide the leaky abstractions and try to bolt on a more database-like semantics:\n",
    "  * ksqlDB\n",
    "  * Flink SQL\n",
    "  * ...\n",
    "\n",
    "* Problematic. In software architecture, you cannot entirely hide leaky abstractions in your core engine, and you cannot entirely bolt on a completely different semantics.\n",
    "\n",
    "* This is why ksqlDB has failed, and why Flink SQL can almost never work on its own - you still need the Datastream API (which Confluent doesn't even offer yet on Confluent Cloud) to fill the gaps.\n",
    "\n",
    "## Challenging The Assumptions Behind \"Classical\" Stream Processing\n",
    "\n",
    "* There is a diaspora of stream processing engines that do challenge these assumptions:\n",
    "  * Differential Dataflow (DD; McSherry 2014) - Materialize, Pathway\n",
    "  * Database Stream Processor (DBSP; Budiu et al. 2022) - Feldera\n",
    "\n",
    "* Low adoption, yes.\n",
    "\n",
    "* Few people actually understand the underpinnings - too theoretical/academic.\n",
    "\n",
    "* But does this mean we should keep ignoring them?\n",
    "\n",
    "* Who of you as ever used one of them?\n",
    "\n",
    "* Do you even know what they are about?\n",
    "\n",
    "## New Assumptions\n",
    "\n",
    "* New assumptions:\n",
    "  * single binary vs. horizontal scaling\n",
    "  * global state/clock vs. local operator state/clock\n",
    "  * a mathematically sound theory vs. ad-hoc operator semantics\n",
    "\n",
    "* This is what you trade-off now:\n",
    "  * \"database-like\" semantics instead of extreme scale\n",
    "  * a sound \"database-like\" abstraction instead of leaky abstractions\n",
    "\n",
    "* Much more appealing to non-stream processing nerds?\n",
    "\n",
    "## DBSP\n",
    "\n",
    "* Few people on earth have really ever fully understood DD - except its inventor, Frank McSherry ;-)\n",
    "\n",
    "* DBSP is a simplified (but still very academic) mathematical foundation for database-like stream processing based on ideas from DD (https://arxiv.org/abs/2203.16684).\n",
    "\n",
    "* Coming from VMware research (main researchers: Mihai Budiu, Leonid Ryzhyk)\n",
    "\n",
    "* Vendor: Feldera\n",
    "\n",
    "* Feldera claims:\n",
    "  * They can seamlessly migrate existing Spark batch jobs to Feldera without changing the 10K lines of SQL over many dozens of tables and views with hundreds of joins, aggregates, unions, distincts, deeply nested subqueries and more - same semantics for stream processing and batch! (https://www.feldera.com/blog/how-feldera-customers-slash-cloud-spend).\n",
    "  * Fully incremental: They can save a lot of compute and memory for their customers - from 50+ node Spark cluster down to 1-2 Feldera compute nodes - updating the views in milliseconds.\n",
    "\n",
    "* Rust implementation: https://github.com/feldera/feldera\n",
    "\n",
    "* First Python implementation (PyDBSP) by Bruno Cardona/Rucy: https://github.com/brurucy/pydbsp\n",
    "\n",
    "## Unchaining Stream Processing\n",
    "\n",
    "* In my view, the growth of stream processing has been held off by:\n",
    "  * It all started with a focus on a very small set of real-time use cases of extreme scale.\n",
    "  * The initial assumptions and architectural decisions underlying the main \"classical\" stream processing systems optimize for this - a very small set of real-time use cases of extreme scale.\n",
    "  * The result is a niche technology that will never be able to attract many to switch from batch to stream processing.\n",
    "  * Worse - even the bigger players are now essentially happily retreating back to batch!\n",
    "\n",
    "* What if we drop these initial assumptions and architectural decisions and build a new foundation? And Feldera shows that you can still optimize that new foundation in a way that *does* allow extreme scale :)\n",
    "\n",
    "* If we reboot stream processing and with the new assumptions behind DBSP?\n",
    "\n",
    "* To unchain stream processing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef96a0",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c6a9a",
   "metadata": {},
   "source": [
    "# 4 Towards A Kafka Streams For Python Based On DBSP\n",
    "\n",
    "## Kafi\n",
    "\n",
    "* The Swiss Army Knife for Kafka. A Python library for all things Kafka (https://github.com/xdgrulez/kafi).\n",
    "\n",
    "* Offers:\n",
    "  * For all kinds of Kafka flavors...\n",
    "    * Direct Kafka API (based on confluent-kafka)\n",
    "    * Confluent REST Proxy\n",
    "    * Emulated Kafka:\n",
    "      * Local disk\n",
    "      * S3\n",
    "      * Azure Blob Storage\n",
    "  * ...producing, consuming, metadata (watermarks, consumer groups...), Schema Registry (Avro, Protobuf, JSONSchema)\n",
    "  * simple stateless stream processing (foreach, map, flatmap...)\n",
    "  * add ons - e.g. message chunking, copy consumer group offsets, get topic statistics etc. pp.\n",
    "  * Pandas support (e.g. read from Kafka, write to Excel sheet or the other way round).\n",
    "  * Incredibly useful for scripting anything around Kafka, e.g. topic migrations.\n",
    "\n",
    "## Kafi Streams\n",
    "\n",
    "* Kafi extension for complex stateful stream processing.\n",
    "\n",
    "* Take the DevX from Kafka Streams but take (Py)DBSP as the underlying stream processing engine.\n",
    "\n",
    "* That is, start from the new assumptions:\n",
    "  * single binary vs. horizontal scaling\n",
    "  * global state/clock vs. local operator state/clock\n",
    "  * a mathematically sound theory vs. ad-hoc operator semantics\n",
    "\n",
    "* To get:\n",
    "  * \"database-like\" semantics instead of extreme scale\n",
    "  * a sound \"database-like\" abstraction instead of leaky abstractions\n",
    "\n",
    "* Here is a very very early prototype...\n",
    "\n",
    "## Already Implemented\n",
    "\n",
    "* A small subset of operators (filter, map, join).\n",
    "* Checkpointing to all Kafi Kafka flavors (including emulated Kafka on S3 and Azure Blob Storage) - so you can even use Kafka directly for checkpointing :)\n",
    "\n",
    "## TODOs...\n",
    "\n",
    "* Implement the remaining operators (starting point: https://github.com/brurucy/pydbsp/blob/master/notebooks/sql.ipynb)\n",
    "* Only then optimize (no premature optimization!)\n",
    "  * Garbage collection\n",
    "  * At a later stage, maybe replace PyDBSP with the Rust implementation of DBSP\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
